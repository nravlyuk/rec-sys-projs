{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from urllib.request import urlopen\n",
    "import scipy.optimize\n",
    "import random\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDataFromURL(fname):\n",
    "    for l in urlopen(fname):\n",
    "        yield eval(l)\n",
    "\n",
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "        \n",
    "def ber_report(pred, y, acc = False):\n",
    "    if acc:\n",
    "        correct = pred == y\n",
    "        accuracy = sum(correct) / len(correct)\n",
    "    # True positives, false positives, etc.\n",
    "    TP_ = np.logical_and(pred, y)\n",
    "    FP_ = np.logical_and(pred, np.logical_not(y))\n",
    "    TN_ = np.logical_and(np.logical_not(pred), np.logical_not(y))\n",
    "    FN_ = np.logical_and(np.logical_not(pred), y)\n",
    "\n",
    "    TP = sum(TP_)/len(y)\n",
    "    FP = sum(FP_)/len(y)\n",
    "    TN = sum(TN_)/len(y)\n",
    "    FN = sum(FN_)/len(y)\n",
    "    TPR = TP / (TP+FN)\n",
    "    TNR = TN / (TN+FP)\n",
    "    FPR = FP / (FP+TN)\n",
    "    FNR = FN / (TP+FN)\n",
    "\n",
    "    BER = 1 - 0.5 * (TP / (TP + FN) + TN / (TN + FP))\n",
    "\n",
    "    if acc:\n",
    "        print(\"Accuracy: {}\".format(accuracy))\n",
    "    print(\"BER: {}\".format(BER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading data...\")\n",
    "# Download from http://jmcauley.ucsd.edu/cse258/data/amazon/book_descriptions_50000.json\n",
    "data = list(parseData(\"data/beer_50000.json\"))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnostics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regressor:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84848\n",
      "BER: 0.16180782764368185\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regressor:\")\n",
    "\n",
    "#Setting categories\n",
    "categoryCounts = defaultdict(int)\n",
    "for d in data:\n",
    "    categoryCounts[d['beer/style']] += 1\n",
    "\n",
    "categories = [c for c in categoryCounts if categoryCounts[c] > 1000]\n",
    "catID = dict(zip(list(categories),range(len(categories))))\n",
    "\n",
    "#Finding data set / splitting in train/test\n",
    "data_set = data\n",
    "        \n",
    "random.shuffle(data_set)\n",
    "data_train = data_set[:len(data_set)//2]\n",
    "data_test = data_set[len(data_set)//2:]\n",
    "\n",
    "def feature(datum):\n",
    "    catOneHot = [0]*len(categories)\n",
    "    if datum['beer/style'] in catID.keys():\n",
    "        catOneHot[catID[datum['beer/style']]] = 1\n",
    "    feat = catOneHot\n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "y_train = [1 if d['beer/ABV'] > 7 else 0 for d in data_train]\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "y_test = [1 if d['beer/ABV'] > 7 else 0 for d in data_test]\n",
    "\n",
    "#Train on train set\n",
    "mod = linear_model.LogisticRegression(C=10.0, class_weight='balanced')\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "#Test on test set\n",
    "pred = mod.predict(X_test)\n",
    "ber_report(pred, y_test, acc = True) # acc = True to report accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two  additional  features: a  vector  of  five  ratings; and the review length\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.14544004773957242\n"
     ]
    }
   ],
   "source": [
    "print(\"Two  additional  features: a  vector  of  five  ratings; and the review length\")\n",
    "\n",
    "def feature(datum):\n",
    "    catOneHot = [0]*len(categories)\n",
    "    if datum['beer/style'] in catID.keys():\n",
    "        catOneHot[catID[datum['beer/style']]] = 1\n",
    "    \n",
    "    feat = catOneHot\n",
    "    feat.extend([len(datum['review/text']), datum['review/appearance'], datum['review/palate'],datum['review/taste'],datum['review/overall'],datum['review/aroma']]) \n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "y_train = [1 if d['beer/ABV'] > 7 else 0 for d in data_train]\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "y_test = [1 if d['beer/ABV'] > 7 else 0 for d in data_test]\n",
    "\n",
    "#Normalize:\n",
    "X_train = X_train / X_train.max(axis=0)\n",
    "X_test = X_test / X_test.max(axis=0)\n",
    "\n",
    "#Train on train set\n",
    "mod = linear_model.LogisticRegression(C=10.0, class_weight='balanced', max_iter=250)\n",
    "mod.fit(X_train, y_train)\n",
    "\n",
    "#Test on test set\n",
    "pred = mod.predict(X_test)\n",
    "ber_report(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete regularization pipeline with the balanced classifier:\n",
      "C = 1e-06:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.49996247936365\n",
      "    Validation BER: 0.5\n",
      "          Test BER: 0.5\n",
      "\n",
      "C = 1e-05:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.4994371904547501\n",
      "    Validation BER: 0.4997005091344714\n",
      "          Test BER: 0.4997755163124813\n",
      "\n",
      "C = 0.0001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.26087534712534577\n",
      "    Validation BER: 0.26330267744422264\n",
      "          Test BER: 0.26148185059546947\n",
      "\n",
      "C = 0.001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.1614235546699906\n",
      "    Validation BER: 0.15693365078747779\n",
      "          Test BER: 0.16500891195352096\n",
      "\n",
      "Based on these values, I would choose the C=10**(-3) classifier as it shows the best BER on average.\n"
     ]
    }
   ],
   "source": [
    "print(\"Complete regularization pipeline with the balanced classifier:\")\n",
    "\n",
    "#Split test sat into validation/test sets:\n",
    "data_valid = data_test[:len(data_test)//2]\n",
    "data_test = data_test[len(data_test)//2:]\n",
    "\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "y_train = [1 if d['beer/ABV'] > 7 else 0 for d in data_train]\n",
    "X_valid = np.array([feature(d) for d in data_valid])\n",
    "y_valid = [1 if d['beer/ABV'] > 7 else 0 for d in data_valid]\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "y_test = [1 if d['beer/ABV'] > 7 else 0 for d in data_test]\n",
    "\n",
    "#Normalize:\n",
    "X_train = X_train / X_train.max(axis=0)\n",
    "X_valid = X_valid / X_valid.max(axis=0)\n",
    "X_test = X_test / X_test.max(axis=0)\n",
    "\n",
    "#Train on train set, report BER(train/validation/test) for each C:\n",
    "\n",
    "def test_C(c):\n",
    "    print(\"C = {}:\".format(c))\n",
    "    #Train/report on train set\n",
    "    print(\"Train \".rjust(15), end = '')\n",
    "    mod = linear_model.LogisticRegression(C=c, class_weight='balanced')\n",
    "    mod.fit(X_train, y_train)\n",
    "    pred = mod.predict(X_train)\n",
    "    ber_report(pred, y_train)\n",
    "    \n",
    "    #Report on validation set\n",
    "    print(\"Validation \".rjust(15), end = '')\n",
    "    pred = mod.predict(X_valid)\n",
    "    ber_report(pred, y_valid)\n",
    "\n",
    "    #Report on test set\n",
    "    print(\"Test \".rjust(15), end = '')\n",
    "    pred = mod.predict(X_test)\n",
    "    ber_report(pred, y_test)\n",
    "    \n",
    "    print()\n",
    "\n",
    "c_range = [10**(-6), 10**(-5), 10**(-4), 10**(-3)]\n",
    "for c in c_range:\n",
    "    test_C(c)\n",
    "\n",
    "print(\"Based on these values, I would choose the C=10**(-3) classifier as it shows the best BER on average.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation study:\n",
      "\n",
      "\n",
      "Beer Style Ablated:\n",
      "C = 1e-06:\n",
      "         Train BER: 0.5"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Validation BER: 0.5\n",
      "          Test BER: 0.5\n",
      "\n",
      "C = 1e-05:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.5\n",
      "    Validation BER: 0.5\n",
      "          Test BER: 0.5\n",
      "\n",
      "C = 0.0001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.494131919034825\n",
      "    Validation BER: 0.4933164204843522\n",
      "          Test BER: 0.4920800755718019\n",
      "\n",
      "C = 0.001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.3730568045078554\n",
      "    Validation BER: 0.37629545746123716\n",
      "          Test BER: 0.3783544838963886\n",
      "\n",
      "\n",
      "\n",
      "Ratings Ablated:\n",
      "C = 1e-06:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.2660893335432484\n",
      "    Validation BER: 0.2692566659351723\n",
      "          Test BER: 0.2674782428053839\n",
      "\n",
      "C = 1e-05:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.1638418069290517\n",
      "    Validation BER: 0.16366437619427265\n",
      "          Test BER: 0.17061035486377207\n",
      "\n",
      "C = 0.0001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.16158390284092605\n",
      "    Validation BER: 0.15753481877098863\n",
      "          Test BER: 0.16608464334025552\n",
      "\n",
      "C = 0.001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.16162673306192998\n",
      "    Validation BER: 0.15753481877098863\n",
      "          Test BER: 0.16608464334025552\n",
      "\n",
      "\n",
      "\n",
      "Review Length Ablated:\n",
      "C = 1e-06:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.49996247936365\n",
      "    Validation BER: 0.5\n",
      "          Test BER: 0.5\n",
      "\n",
      "C = 1e-05:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.4993996698184001\n",
      "    Validation BER: 0.4997005091344714\n",
      "          Test BER: 0.49962586052080216\n",
      "\n",
      "C = 0.0001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.25958796568882114\n",
      "    Validation BER: 0.26289966109486085\n",
      "          Test BER: 0.26114696425104345\n",
      "\n",
      "C = 0.001:\n",
      "         Train "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER: 0.1616699168267064\n",
      "    Validation BER: 0.1571692773607436\n",
      "          Test BER: 0.16513930129831667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Ablation study:\")\n",
    "\n",
    "print(\"\\n\\nBeer Style Ablated:\")\n",
    "\n",
    "def feature(datum):\n",
    "    feat = [len(datum['review/text']), datum['review/appearance'], datum['review/palate'],datum['review/taste'],datum['review/overall'],datum['review/aroma']] \n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "#Set inputs + normalize\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "X_valid = np.array([feature(d) for d in data_valid])\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "X_train = X_train / X_train.max(axis=0)\n",
    "X_valid = X_valid / X_valid.max(axis=0)\n",
    "X_test = X_test / X_test.max(axis=0)\n",
    "\n",
    "for c in c_range:\n",
    "    test_C(c)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"\\n\\nRatings Ablated:\")\n",
    "\n",
    "def feature(datum):\n",
    "    catOneHot = [0]*len(categories)\n",
    "    if datum['beer/style'] in catID.keys():\n",
    "        catOneHot[catID[datum['beer/style']]] = 1\n",
    "    \n",
    "    feat = catOneHot\n",
    "    feat.append(len(datum['review/text'])) \n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "#Set inputs + normalize\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "X_valid = np.array([feature(d) for d in data_valid])\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "X_train = X_train / X_train.max(axis=0)\n",
    "X_valid = X_valid / X_valid.max(axis=0)\n",
    "X_test = X_test / X_test.max(axis=0)\n",
    "\n",
    "for c in c_range:\n",
    "    test_C(c)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"\\n\\nReview Length Ablated:\")\n",
    "\n",
    "def feature(datum):\n",
    "    catOneHot = [0]*len(categories)\n",
    "    if datum['beer/style'] in catID.keys():\n",
    "        catOneHot[catID[datum['beer/style']]] = 1\n",
    "    \n",
    "    feat = catOneHot\n",
    "    feat.extend([datum['review/appearance'], datum['review/palate'],datum['review/taste'],datum['review/overall'],datum['review/aroma']]) \n",
    "    feat.append(1)\n",
    "    return feat\n",
    "\n",
    "#Set inputs + normalize\n",
    "X_train = np.array([feature(d) for d in data_train])\n",
    "X_valid = np.array([feature(d) for d in data_valid])\n",
    "X_test = np.array([feature(d) for d in data_test])\n",
    "X_train = X_train / X_train.max(axis=0)\n",
    "X_valid = X_valid / X_valid.max(axis=0)\n",
    "X_test = X_test / X_test.max(axis=0)\n",
    "\n",
    "for c in c_range:\n",
    "    test_C(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Egonet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SD-PC\\Anaconda3\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "edges = set()\n",
    "nodes = set()\n",
    "for edge in open(\"data/egonet.txt\", 'r'):\n",
    "    x,y = edge.split()\n",
    "    x,y = int(x),int(y)\n",
    "    edges.add((x,y))\n",
    "    edges.add((y,x))\n",
    "    nodes.add(x)\n",
    "    nodes.add(y)\n",
    "\n",
    "G = nx.Graph()\n",
    "for e in edges:\n",
    "    G.add_edge(e[0],e[1])\n",
    "nx.draw(G)\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected component:\n",
      "Number of connected components: 3\n",
      "Number of nodes in the largest connected component: 40\n"
     ]
    }
   ],
   "source": [
    "print(\"Connected component:\")\n",
    "\n",
    "to_process = set(nodes)\n",
    "processed = set()\n",
    "\n",
    "clusters = []\n",
    "while len(to_process) > 0:\n",
    "    curr = set()\n",
    "    curr.add(to_process.pop())\n",
    "    added = True\n",
    "    while len(set(curr - processed)) > 0 and len(to_process) > 0:               \n",
    "        check = set(curr - processed)\n",
    "        x = check.pop()  \n",
    "        curr.add(x)\n",
    "        processed.add(x)\n",
    "        for e in edges:\n",
    "            if e[0] == x:\n",
    "                if e[1] in to_process:\n",
    "                    to_process.remove(e[1])\n",
    "                curr.add(e[1])\n",
    "            if e[1] == x:\n",
    "                if e[0] in to_process:\n",
    "                    to_process.remove(e[0])\n",
    "                curr.add(e[1])\n",
    "    clusters.append(set(curr))\n",
    "    \n",
    "print(\"Number of connected components: {}\".format(nx.number_connected_components(G)))\n",
    "print(\"Number of nodes in the largest connected component: {}\".format(max(len(c) for c in clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized-cut cost:\n",
      "Normalized Cut Cost: 0.42240587695133147\n"
     ]
    }
   ],
   "source": [
    "print(\"Normalized-cut cost:\")\n",
    "\n",
    "def norm_cut_cost(t, b):\n",
    "    top_degree = sum([G.degree(n) for n in t])\n",
    "    bot_degree = sum([G.degree(n) for n in b])\n",
    "    cut = 0\n",
    "    for e in edges:\n",
    "        if e[0] in t and e[1] in b:\n",
    "            cut+=1\n",
    "    cost = 1/2*(cut/top_degree + cut/bot_degree)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "largest_comp = list(clusters[0])\n",
    "largest_comp.sort()\n",
    "top = largest_comp[len(largest_comp)//2:]\n",
    "bot = largest_comp[:len(largest_comp)//2]\n",
    "\n",
    "print(\"Normalized Cut Cost: {}\".format(norm_cut_cost(top, bot)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top:\n",
      " {864, 804, 876, 861, 878, 882, 884, 729, 886, 888, 825, 893, 889, 863}\n",
      "\n",
      "Bot:\n",
      " {769, 772, 708, 774, 840, 713, 719, 856, 798, 800, 803, 805, 869, 745, 810, 811, 747, 880, 753, 819, 823, 697, 890, 828, 830, 703}\n",
      "Normalized Cut Cost: 0.09817045961624274\n"
     ]
    }
   ],
   "source": [
    "top = set(top)\n",
    "bot = set(bot)\n",
    "\n",
    "minimised = False\n",
    "while not minimised:\n",
    "    minimised = True\n",
    "    t = set(top)\n",
    "    b = set(bot)\n",
    "    cost = norm_cut_cost(list(top), list(bot))\n",
    "    min_cost = cost\n",
    "    for i in largest_comp:\n",
    "        if i in t:\n",
    "            t.remove(i)\n",
    "            b.add(i)\n",
    "        else:\n",
    "            b.remove(i)\n",
    "            t.add(i)\n",
    "        c = norm_cut_cost(list(t), list(b))\n",
    "        if c < min_cost:\n",
    "            min_cost = c\n",
    "            min_t = set(t)\n",
    "            min_b = set(b)\n",
    "            minimised = False\n",
    "        t = set(top)\n",
    "        b = set(bot)\n",
    "    if not minimised:\n",
    "        top = set(min_t)\n",
    "        bot = set(min_b)\n",
    "\n",
    "print(\"Top:\\n\", top)\n",
    "print(\"\\nBot:\\n\", bot)\n",
    "\n",
    "print(\"Normalized Cut Cost: {}\".format(norm_cut_cost(list(top), list(bot))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
